{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import getpass\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import chain\n",
    "import datetime\n",
    "from fractions import Fraction\n",
    "from collections import Counter\n",
    "from pymongo import UpdateOne\n",
    "import statistics\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath_book = \"D:\\\\University\\Môn học\\Ứng dụng Big Data\\Project\\Datasets\\Amazon Books Reviews\\\\books_data.csv\"\n",
    "# filepath = \"D:\\\\University\\Môn học\\Ứng dụng Big Data\\Project\\Datasets\\Amazon Books Reviews\\Books_rating.csv\"\n",
    "\n",
    "# df_book = pd.read_csv(filepath_book)\n",
    "# df_review = pd.read_csv(filepath)\n",
    "\n",
    "password = 'Ngthiennhan2002.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_index = 0\n",
    "# chunk_size = 375000\n",
    "\n",
    "# for i in range(1, 9):\n",
    "#     end_index = start_index + chunk_size\n",
    "#     df_chunk = df_review.iloc[start_index:end_index]\n",
    "#     file_name = f\"D:\\\\University\\\\Môn học\\\\Ứng dụng Big Data\\\\Project\\\\Datasets\\\\Amazon Books Reviews\\\\Books_rating_{i}_375k.csv\"\n",
    "#     df_chunk.to_csv(file_name, index=False)\n",
    "#     start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cryptography\\x509\\base.py:594: CryptographyDeprecationWarning: Parsed a negative serial number, which is disallowed by RFC 5280.\n",
      "  return rust_x509.load_der_x509_certificate(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375000\n",
      "375000\n",
      "375000\n",
      "375000\n",
      "375000\n",
      "375000\n",
      "375000\n",
      "375000\n",
      "212404\n"
     ]
    }
   ],
   "source": [
    "API_1 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.mhlvibl.mongodb.net/'\n",
    "# API_1 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.yl3o8ez.mongodb.net/'\n",
    "API_2 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.bzvhw41.mongodb.net/'\n",
    "API_3 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.jrdv2e2.mongodb.net/'\n",
    "API_4 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.tq84xea.mongodb.net/'\n",
    "API_5 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.i2p6hb8.mongodb.net/'\n",
    "API_6 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.ppuo86b.mongodb.net/'\n",
    "API_7 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.xjtimov.mongodb.net/'\n",
    "API_8 = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.5ihto1h.mongodb.net/'\n",
    "API_items = f'mongodb+srv://ngthiennhan2002:{password}@cluster0.2qutpiu.mongodb.net/'\n",
    "\n",
    "try:\n",
    "    # Create two MongoDB clients using MongoClient with two APIs\n",
    "    client_1 = MongoClient(API_1)\n",
    "    client_2 = MongoClient(API_2)\n",
    "    client_3 = MongoClient(API_3)\n",
    "    client_4 = MongoClient(API_4)\n",
    "    client_5 = MongoClient(API_5)\n",
    "    client_6 = MongoClient(API_6)\n",
    "    client_7 = MongoClient(API_7)\n",
    "    client_8 = MongoClient(API_8)\n",
    "    client_items = MongoClient(API_items)\n",
    "    \n",
    "    # Variables to save names of databases and collections\n",
    "    database_name = 'db'\n",
    "    review_collection_name = 'Reviews'\n",
    "    book_collection_name = 'Books'\n",
    "    author_collection_name = 'Authors'\n",
    "    categories_collection_name = 'Categories'\n",
    "    temp_collection_name = 'Temp'\n",
    "    user_collection_name = 'Users'\n",
    "\n",
    "    db_1 = client_1[database_name]\n",
    "    review_collection_1 = db_1[review_collection_name]\n",
    "\n",
    "    db_2 = client_2[database_name]\n",
    "    review_collection_2 = db_2[review_collection_name]\n",
    "    \n",
    "    db_3 = client_3[database_name]\n",
    "    review_collection_3 = db_3[review_collection_name]\n",
    "\n",
    "    db_4 = client_4[database_name]\n",
    "    review_collection_4 = db_4[review_collection_name]\n",
    "    \n",
    "    db_5 = client_5[database_name]\n",
    "    review_collection_5 = db_5[review_collection_name]\n",
    "\n",
    "    db_6 = client_6[database_name]\n",
    "    review_collection_6 = db_6[review_collection_name]\n",
    "    \n",
    "    db_7 = client_7[database_name]\n",
    "    review_collection_7 = db_7[review_collection_name]\n",
    "\n",
    "    db_8 = client_8[database_name]\n",
    "    review_collection_8 = db_8[review_collection_name]\n",
    "    \n",
    "    db_items = client_items[database_name]\n",
    "    book_collection = db_items[book_collection_name]\n",
    "    author_collection = db_items[author_collection_name]\n",
    "    categories_collection = db_items[categories_collection_name]\n",
    "    temp_collection = db_items[temp_collection_name]\n",
    "    users_collection = db_items[user_collection_name]\n",
    "except:\n",
    "    print(\"Incorrect password or cannot connect to MongoDB at this time\")\n",
    "    \n",
    "# Test if the documents are read successfully\n",
    "print(review_collection_1.count_documents({}))\n",
    "print(review_collection_2.count_documents({}))\n",
    "print(review_collection_3.count_documents({}))\n",
    "print(review_collection_4.count_documents({}))\n",
    "print(review_collection_5.count_documents({}))\n",
    "print(review_collection_6.count_documents({}))\n",
    "print(review_collection_7.count_documents({}))\n",
    "print(review_collection_8.count_documents({}))\n",
    "print(book_collection.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lengths of collections\n",
    "total_book = book_collection.count_documents({})\n",
    "total_review = 375000\n",
    "\n",
    "# Convert book collection into pandas DataFrame (with progress bar)\n",
    "# with tqdm(total=total_book, desc='Converting book collection') as pbar:\n",
    "#     df_book = pd.DataFrame(list(book_collection.find()))\n",
    "#     pbar.update(len(df_book))\n",
    "#     pbar.close()\n",
    "\n",
    "# with tqdm(total=total_review, desc='Converting review collection 1') as pbar:\n",
    "#     df_review_1 = pd.DataFrame(list(review_collection_1.find()))\n",
    "#     pbar.update(len(df_review_1))\n",
    "#     pbar.close()\n",
    "\n",
    "# with tqdm(total=total_review, desc='Converting review collection 2') as pbar:\n",
    "#     df_review_2 = pd.DataFrame(list(review_collection_2.find()))\n",
    "#     pbar.update(len(df_review_2))\n",
    "#     pbar.close()\n",
    "    \n",
    "# with tqdm(total=total_review, desc='Converting review collection 3') as pbar:\n",
    "#     df_review_3 = pd.DataFrame(list(review_collection_3.find()))\n",
    "#     pbar.update(len(df_review_3))\n",
    "#     pbar.close()\n",
    "\n",
    "# with tqdm(total=total_review, desc='Converting review collection 4') as pbar:\n",
    "#     df_review_4 = pd.DataFrame(list(review_collection_4.find()))\n",
    "#     pbar.update(len(df_review_4))\n",
    "#     pbar.close()\n",
    "    \n",
    "# with tqdm(total=total_review, desc='Converting review collection 5') as pbar:\n",
    "#     df_review_5 = pd.DataFrame(list(review_collection_5.find()))\n",
    "#     pbar.update(len(df_review_5))\n",
    "#     pbar.close()\n",
    "\n",
    "# with tqdm(total=total_review, desc='Converting review collection 6') as pbar:\n",
    "#     df_review_6 = pd.DataFrame(list(review_collection_6.find()))\n",
    "#     pbar.update(len(df_review_6))\n",
    "#     pbar.close()\n",
    "    \n",
    "# with tqdm(total=total_review, desc='Converting review collection 7') as pbar:\n",
    "#     df_review_7 = pd.DataFrame(list(review_collection_7.find()))\n",
    "#     pbar.update(len(df_review_7))\n",
    "#     pbar.close()\n",
    "\n",
    "# with tqdm(total=total_review, desc='Converting review collection 8') as pbar:\n",
    "#     df_review_8 = pd.DataFrame(list(review_collection_8.find()))\n",
    "#     pbar.update(len(df_review_8))\n",
    "#     pbar.close()\n",
    "\n",
    "# print(\"--- Finished converting to DataFrame ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two df_review_1 and df_review_2\n",
    "# with tqdm(total=total_review, desc='Combining 2 review collections') as pbar:\n",
    "#     df_review = pd.concat([df_review_1, df_review_2, df_review_3, df_review_4, df_review_5, df_review_6, df_review_7, df_review_8])\n",
    "#     pbar.update(len(df_review))\n",
    "#     pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(s):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Title\\\n",
    "Missing values: 1 book thiếu Title -> điền thủ công bằng cách vào Link\\\n",
    "Noises: Chuyển chuỗi về kí tự thường và loại bỏ các kí tự đặc biệt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count = 0\n",
    "\n",
    "# # for temp in temp_collection.find():\n",
    "# #     if temp['field'] == 'book_title':\n",
    "# #         temp_id = temp['_id']\n",
    "# #         count = int(temp['value'])\n",
    "# #         break\n",
    "\n",
    "# progress_bar = tqdm(total=total_book, desc='Preprocessing book collection\\'s Title', position=0)\n",
    "\n",
    "# title_list = []\n",
    "\n",
    "# for book in book_collection.find():\n",
    "#     title = book['Title']\n",
    "#     if type(title) is not str: \n",
    "#         title = str(title)\n",
    "#     title = title.lower()\n",
    "#     title = remove_special_characters(title)\n",
    "#     title = re.sub(r'\\s+', ' ', title)\n",
    "#     title_list.append(({'_id': book['_id']}, {'$set': {'Title': title}}))\n",
    "#         # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': count}})\n",
    "#     progress_bar.update(1)\n",
    "    \n",
    "# progress_bar.close()\n",
    "# # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "# for title in title_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             title[0],\n",
    "#             title[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# # result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Description\n",
    "- Missing values: Bỏ qua\n",
    "- Noises: Chuyển chuỗi về chữ thường và loại bỏ các kí tự đặc biệt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=total_book, desc='Preprocessing book collection\\'s Description', position=0)\n",
    "\n",
    "# description_list = []\n",
    "\n",
    "# for book in book_collection.find():\n",
    "#     if 'description' in book:\n",
    "#         description = str(book['description'])\n",
    "#         description = description.lower()\n",
    "#         description = remove_special_characters(description)\n",
    "#         description = re.sub(r'\\s+', ' ', description)\n",
    "#         description_list.append(({'_id': book['_id']}, {'$set': {'description': description}}))\n",
    "#     # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': count}})\n",
    "#     progress_bar.update(1)\n",
    "\n",
    "# progress_bar.close()\n",
    "# # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "# for description in description_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             description[0],\n",
    "#             description[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# # result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Authors và Categories\n",
    "- Missing values: Bỏ qua\n",
    "- Tạo danh sách chuỗi các tác giả\n",
    "- Noises: Chuyển chuỗi về chữ thường, loại bỏ các kí tự đặc biệt và xử lý các biến thể tên tác giả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors = []\n",
    "# categories = []\n",
    "\n",
    "# for author in author_collection.find():\n",
    "#     author_id = author['_id']\n",
    "#     authors.append(({'_id': author_id}, {'$set': {'Value': author['Value']}}))\n",
    "    \n",
    "# for category in categories_collection.find():\n",
    "#     category_id = category['_id']\n",
    "#     categories.append(({'_id': category_id}, {'$set': {'Value': category['Value']}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=author_collection.count_documents({}), desc='Preprocessing Authors\\'s collection', position=0)\n",
    "\n",
    "# author_list = []\n",
    "\n",
    "# for author in author_collection.find():\n",
    "#     author_name = author['Value']\n",
    "#     if author_name:\n",
    "#         author_name = author_name.lower()\n",
    "#         author_name = remove_special_characters(author_name)\n",
    "#         author_name = re.sub(r'\\s+', ' ', author_name)\n",
    "#         author_list.append(({'_id': author['_id']}, {'$set': {'Value': author_name}}))\n",
    "#     # author_list.append({'_id': temp_id}, {'$set': {'Value': count}})\n",
    "#     progress_bar.update(1)\n",
    "\n",
    "# progress_bar.close()\n",
    "# # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "# for author in author_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             {'_id': author[0]['_id']},\n",
    "#             {'$set': {'Value': author[1]['$set']['Value']}},\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# result = author_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=categories_collection.count_documents({}), desc='Preprocessing Categories\\'s collection', position=0)\n",
    "\n",
    "# category_list = []\n",
    "\n",
    "# for category in categories_collection.find():\n",
    "#     category_name = category['Value']\n",
    "#     category_name = category_name.lower()\n",
    "#     category_name = remove_special_characters(category_name)\n",
    "#     category_name = re.sub(r'\\s+', ' ', category_name)\n",
    "#     category_list.append(({'_id': category['_id']}, {'$set': {'Value': category_name}}))\n",
    "#     # temp_collection.update_one({'_id': temp_id}, {'$set': {'Value': count}})\n",
    "#     progress_bar.update(1)\n",
    "\n",
    "# progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "\n",
    "# for category in category_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             category[0],\n",
    "#             category[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# result = categories_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Publisher\n",
    "- Missing values: Bỏ qua\n",
    "- Noises: Loại bỏ kí tự đặc biệt, chuyển từ chữ hoa sang chữ thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=total_book, desc='Preprocessing book collection\\'s Publisher', position=0)\n",
    "\n",
    "# publisher_list = []\n",
    "\n",
    "# for book in book_collection.find():\n",
    "#     if 'publisher' in book:\n",
    "#         publisher = book['publisher']\n",
    "#         # print(publisher)\n",
    "#         if type(publisher) is int:\n",
    "#             publisher = str(publisher)\n",
    "#         publisher = publisher.lower()\n",
    "#         publisher = remove_special_characters(publisher)\n",
    "#         publisher = re.sub(r'\\s+', ' ', publisher)\n",
    "#         publisher_list.append(({'_id': book['_id']}, {'$set': {'publisher': publisher}}))\n",
    "#         # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': count}})\n",
    "#     progress_bar.update(1)\n",
    "    \n",
    "# progress_bar.close()\n",
    "# # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "# for publisher in publisher_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             publisher[0],\n",
    "#             publisher[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# result = book_collection.bulk_write(update_requests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường publishedDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# def convert_to_datetime(date_str):\n",
    "#     formats = ['%Y', '%Y-%m', '%m-%Y', '%Y-%m-%d', '%m-%d-%Y', '%Y/%m/%d', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M', '%m/%d/%Y', '%d/%m/%Y']\n",
    "#     if isinstance(date_str, datetime):\n",
    "#         return date_str\n",
    "    \n",
    "#     if isinstance(date_str, int):\n",
    "#         date_str = str(date_str)\n",
    "        \n",
    "#     for fmt in formats:\n",
    "#         try:\n",
    "#             date_obj = datetime.strptime(date_str, fmt)\n",
    "#             if fmt.count('%') == 1:\n",
    "#                 return date_obj.strftime('%Y')\n",
    "#             elif fmt.count('%') == 2:\n",
    "#                 return date_obj.strftime('%Y-%m')\n",
    "#             else:\n",
    "#                 return date_obj.strftime('%Y-%m-%d')\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     return None\n",
    "    \n",
    "# count = 0\n",
    "\n",
    "# a = []\n",
    "\n",
    "# progress_bar = tqdm(total=total_book-count, desc='Preprocessing book collection\\'s Published Date', position=0)\n",
    "\n",
    "# for book in book_collection.find().skip(count):\n",
    "#     if 'publishedDate' in book:\n",
    "#         publishedDate = book['publishedDate']\n",
    "#         if publishedDate:\n",
    "#             try:\n",
    "#                 publishedDate = convert_to_datetime(publishedDate)\n",
    "#                 # book_collection.update_one({'_id': book['_id']}, {'$set': {'publishedDate': publishedDate}})\n",
    "#                 a.append(({'_id': book['_id']}, {'$set': {'publishedDate': publishedDate}}))\n",
    "#             except ValueError:\n",
    "#                 print(\"Error\")\n",
    "#         count += 1\n",
    "#         # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': count}})\n",
    "#     progress_bar.update(1)\n",
    "    \n",
    "# progress_bar.close()\n",
    "# # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "\n",
    "# published_date_list = a\n",
    "\n",
    "# for published_date in published_date_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             published_date[0],\n",
    "#             published_date[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # # Thực hiện bulk write\n",
    "# result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Title (của Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_collections = [review_collection_1,\n",
    "                     review_collection_2,\n",
    "                     review_collection_3,\n",
    "                     review_collection_4,\n",
    "                     review_collection_5,\n",
    "                     review_collection_6,\n",
    "                     review_collection_7,\n",
    "                     review_collection_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, review_collection in enumerate(review_collections):\n",
    "    \n",
    "#     print(f'--- Preprocessing title of review collection {index + 1} ---')\n",
    "#     title_list = []\n",
    "    \n",
    "#     progress_bar = tqdm(total=review_collection.count_documents({}), desc='Preprocessing review collection\\'s Title', position=0)\n",
    "    \n",
    "#     for index_2, review in enumerate(review_collection.find()):\n",
    "#         if 'Title' in review:\n",
    "#             title = review['Title']\n",
    "#             if type(title) is not str: \n",
    "#                 title = str(title)\n",
    "#             # title = title.lower()\n",
    "#             # title = remove_special_characters(title)\n",
    "#             title = re.sub(r'\\s+', ' ', title)\n",
    "#             title_list.append(({'_id': review['_id']}, {'$set': {'Title': title}}))\n",
    "#         # temp_collection.update_one({'_id': temp_id}, {'$set': {'value': count}})\n",
    "#         progress_bar.update(1)\n",
    "        \n",
    "#     progress_bar.close()\n",
    "    \n",
    "#     # Tạo danh sách yêu cầu cập nhật\n",
    "#     update_requests = []\n",
    "    \n",
    "#     for title in title_list:\n",
    "#         update_requests.append(\n",
    "#             UpdateOne(\n",
    "#                 title[0],\n",
    "#                 title[1],\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "#     print(update_requests[:5])\n",
    "\n",
    "#     # # Thực hiện bulk write\n",
    "#     # result = review_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường review/count và trường review/average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sử dụng defaultdict để tổ chức dữ liệu theo 'Title'\n",
    "# title_data = defaultdict(list)\n",
    "\n",
    "# # Thu thập dữ liệu từ các collection\n",
    "# for review_collection in review_collections:\n",
    "#     documents = review_collection.find({'review/score': {'$exists': True}})\n",
    "    \n",
    "#     progress_bar = tqdm(total=review_collection.count_documents({}), desc='Preprocessing review scores', position=0)\n",
    "    \n",
    "#     for document in documents:\n",
    "#         if 'Title' in document:\n",
    "#             title = document['Title']\n",
    "#             title_data[title].append(document['review/score'])\n",
    "#             progress_bar.update(1)\n",
    "\n",
    "#     progress_bar.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=len(title_data), desc='Calculating review scores', position=0)\n",
    "\n",
    "# new_book_scores_list = list()\n",
    "\n",
    "# for title, scores_list in title_data.items():\n",
    "#     count_reviews = len(scores_list)\n",
    "#     if scores_list:\n",
    "#         mean_score = statistics.mean(scores_list)\n",
    "#         median_score = statistics.median(scores_list)\n",
    "#         mode_score = statistics.mode(scores_list)\n",
    "#     else:\n",
    "#         mean_score, median_score, mode_score = 0, 0, 0\n",
    "        \n",
    "#     book_score_info = ({'Title': title}, {'$set': {'review/mean_score': mean_score, \n",
    "#                                                        'review/median_score': median_score,\n",
    "#                                                        'review/mode_score': mode_score,\n",
    "#                                                        'review/count': count_reviews}})\n",
    "#     new_book_scores_list.append((book_score_info))\n",
    "\n",
    "#     progress_bar.update(1)\n",
    "\n",
    "# progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "\n",
    "# for book in new_book_scores_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             book[0],\n",
    "#             book[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # Thực hiện bulk write\n",
    "# # result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews\n",
    "\n",
    "- Noises: Đã thực hiện ở trên\n",
    "- Missing values: Fill theo 'Id' nếu có 'Id' nào chứa Title đó. nếu không có để trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sử dụng defaultdict để tổ chức dữ liệu theo 'Title'\n",
    "# id_data = defaultdict(list)\n",
    "\n",
    "# progress_bar = tqdm(total=len(review_collections), desc='Preprocessing miss Review Titles', position=0)\n",
    "\n",
    "# # Thu thập dữ liệu từ các collection\n",
    "# for review_collection in review_collections:\n",
    "#     documents = review_collection.find({})\n",
    "    \n",
    "#     null_titles = review_collection.find({'Title': {'$exists': False}})\n",
    "    \n",
    "#     for document in null_titles:\n",
    "#         existed_titles_by_id_1 = review_collection_1.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_2 = review_collection_2.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_3 = review_collection_3.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_4 = review_collection_4.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_5 = review_collection_5.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_6 = review_collection_6.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_7 = review_collection_7.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "#         existed_titles_by_id_8 = review_collection_8.find({'Id': document['Id'], 'Title': {'$exists': True}})\n",
    "        \n",
    "#         for existed_review in existed_titles_by_id_1:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_2:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_3:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_4:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_5:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_6:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_7:\n",
    "#             print(existed_review)\n",
    "#         for existed_review in existed_titles_by_id_8:\n",
    "#             print(existed_review)\n",
    "    \n",
    "#     progress_bar.update(1)\n",
    "#     # Tạo danh sách yêu cầu cập nhật\n",
    "#     # update_requests = []\n",
    "\n",
    "#     # for published_date in published_date_list:\n",
    "#     #     update_requests.append(\n",
    "#     #         UpdateOne(\n",
    "#     #             published_date[0],\n",
    "#     #             published_date[1],\n",
    "#     #         )\n",
    "#     #     )\n",
    "        \n",
    "#     # print(update_requests[:5])\n",
    "\n",
    "#     # # Thực hiện bulk write\n",
    "#     # result = review_collection.bulk_write(update_requests)\n",
    "\n",
    "# progress_bar.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết luận: Không có Title bị khuyết nào có thể được điền thông qua chỉ số Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường review/helpfulness\n",
    "- Chuyển từ dạng a/b thành dạng float\n",
    "- Thay missing values = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing title of review collection 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing review collection's Helpfulness: 100%|██████████| 375000/375000 [16:21<00:00, 381.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpdateOne({'_id': ObjectId('6600efb26e1434207a392bf7')}, {'$set': {'review/helpfulness': 1.0}}, False, None, None, None), UpdateOne({'_id': ObjectId('6600efb26e1434207a392bf8')}, {'$set': {'review/helpfulness': 1.0}}, False, None, None, None), UpdateOne({'_id': ObjectId('6600efb26e1434207a392bf9')}, {'$set': {'review/helpfulness': 0.9090909090909091}}, False, None, None, None), UpdateOne({'_id': ObjectId('6600efb26e1434207a392bfa')}, {'$set': {'review/helpfulness': 1.0}}, False, None, None, None), UpdateOne({'_id': ObjectId('6600efb26e1434207a392bfb')}, {'$set': {'review/helpfulness': 1.0}}, False, None, None, None)]\n"
     ]
    }
   ],
   "source": [
    "# for index, review_collection in enumerate(review_collections):\n",
    "    \n",
    "#     print(f'--- Preprocessing title of review collection {index + 1} ---')\n",
    "#     helpfulness_list = []\n",
    "    \n",
    "#     progress_bar = tqdm(total=review_collection.count_documents({}), desc='Preprocessing review collection\\'s Helpfulness', position=0)\n",
    "    \n",
    "#     for index_2, review in enumerate(review_collection.find()):\n",
    "#         if 'review/helpfulness' in review:\n",
    "#             helpfulness_string = review['review/helpfulness']\n",
    "#             helpfulness_string = helpfulness_string.split('/')\n",
    "#             numerator = int(helpfulness_string[0])\n",
    "#             denominator = int(helpfulness_string[1])\n",
    "            \n",
    "#             # Nếu mẫu bằng 0\n",
    "#             if denominator == 0.0 or numerator == 0.0:\n",
    "#                 helpfulness_value = 0.0\n",
    "#             else:\n",
    "#                 helpfulness_value = numerator / denominator\n",
    "#                 if helpfulness_value > 1.0: # Xử lý các outlier lớn hơn 1\n",
    "#                     helpfulness_value = 1.0\n",
    "#         else:\n",
    "#             helpfulness_value = 0.0\n",
    "\n",
    "#         helpfulness_list.append(({'_id': review['_id']}, {'$set': {'review/helpfulness': helpfulness_value}}))\n",
    "#         progress_bar.update(1)\n",
    "        \n",
    "#     progress_bar.close()\n",
    "    \n",
    "#     # Tạo danh sách yêu cầu cập nhật\n",
    "#     update_requests = []\n",
    "    \n",
    "#     for helpfulness in helpfulness_list:\n",
    "#         update_requests.append(\n",
    "#             UpdateOne(\n",
    "#                 helpfulness[0],\n",
    "#                 helpfulness[1],\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "#     print(update_requests[:5])\n",
    "\n",
    "#     # Thực hiện bulk write\n",
    "#     result = review_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trường Authors và Categories\n",
    "- Chuyển về dạng list các tác giả và các danh mục\n",
    "- Chuyển về format chữ thường, loại bỏ kí tự đặc biệt như trong Authors và Categories collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def string_to_list(data):\n",
    "#     '''\n",
    "#     This function gets a list (authors, categories) from a string type\n",
    "    \n",
    "#     Args:\n",
    "#     data -- the input data needed to be converted\n",
    "    \n",
    "#     Returns:\n",
    "#     values -- the converted values (list type)\n",
    "#     '''\n",
    "#     # Process the string data to convert into list type\n",
    "#     values = data.strip(\"[]\").replace(\"'\", \"\")\n",
    "    \n",
    "#     # Remove the quotation marks\n",
    "#     values = values.replace('\"', '')\n",
    "    \n",
    "#     # Split the string to become a list\n",
    "#     values = values.split(\", \")\n",
    "    \n",
    "#     # Regex expression to remove invalid title\n",
    "#     pattern = re.compile(r'^[\\W\\d]+$')  # Remove strings containing only characters which are not \n",
    "\n",
    "#     # Remove invalid authors\n",
    "#     filtered_values = [value for value in values if not pattern.match(value)]\n",
    "    \n",
    "#     # Remove spaces at the beginning and ending of every element in the list\n",
    "#     values = list(value.strip() for value in filtered_values)\n",
    "    \n",
    "#     return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books = book_collection.find({'authors': {'$exists': True}})\n",
    "# progress_bar = tqdm(total=total_book, desc='Preprocessing...', position=0)\n",
    "\n",
    "# author_list = []\n",
    "\n",
    "# for book in books:\n",
    "#     new_authors = []\n",
    "#     authors = book['authors']\n",
    "    \n",
    "#     if (type(authors) == str):\n",
    "#         new_authors = string_to_list(authors)\n",
    "        \n",
    "#     elif (type(authors) == list):\n",
    "#         for author in authors:\n",
    "#             pattern = re.compile(r'^[\\W\\d]+$')  # Remove strings containing only characters which are not \n",
    "\n",
    "#             if author is not pattern.match(author):\n",
    "#                 continue\n",
    "            \n",
    "#             new_authors = authors\n",
    "    \n",
    "#     processed_authors = []\n",
    "#     for author in new_authors:\n",
    "#         author = author.lower()\n",
    "#         author = remove_special_characters(author)\n",
    "#         author = re.sub(r'\\s+', ' ', author)\n",
    "#         processed_authors.append(author)\n",
    "        \n",
    "#     author_list.append(({'_id': book['_id']}, {'$set': {'authors': processed_authors}}))\n",
    "#     progress_bar.update(1)\n",
    "    \n",
    "# progress_bar.close()\n",
    "\n",
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "\n",
    "# for author in author_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             author[0],\n",
    "#             author[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # Thực hiện bulk write\n",
    "# # result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books = book_collection.find({'categories': {'$exists': True}})\n",
    "# progress_bar = tqdm(total=total_book, desc='Preprocessing...', position=0)\n",
    "\n",
    "# category_list = []\n",
    "\n",
    "# for book in books:\n",
    "#     new_categories = []\n",
    "#     categories = book['categories']\n",
    "    \n",
    "#     if (type(categories) == str):\n",
    "#         new_categories = string_to_list(categories)\n",
    "        \n",
    "#     elif (type(categories) == list):\n",
    "#         for category in categories:\n",
    "#             pattern = re.compile(r'^[\\W\\d]+$')  # Remove strings containing only characters which are not \n",
    "\n",
    "#             if category is not pattern.match(category):\n",
    "#                 continue\n",
    "            \n",
    "#             new_categories = categories\n",
    "    \n",
    "#     processed_categories = []\n",
    "#     for category in new_categories:\n",
    "#         category = category.lower()\n",
    "#         category = remove_special_characters(category)\n",
    "#         category = re.sub(r'\\s+', ' ', category)\n",
    "#         processed_categories.append(category)\n",
    "        \n",
    "#     category_list.append(({'_id': book['_id']}, {'$set': {'categories': processed_categories}}))\n",
    "#     progress_bar.update(1)\n",
    "    \n",
    "# progress_bar.close()\n",
    "\n",
    "# # Tạo danh sách yêu cầu cập nhật\n",
    "# update_requests = []\n",
    "\n",
    "# for category in category_list:\n",
    "#     update_requests.append(\n",
    "#         UpdateOne(\n",
    "#             category[0],\n",
    "#             category[1],\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "# print(update_requests[:5])\n",
    "\n",
    "# # Thực hiện bulk write\n",
    "# # result = book_collection.bulk_write(update_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng Model:\n",
    "- SENTIMENT ANALYSIS đối với review/summary và review/text (RoBERTa-base model): biến chuỗi text thành dạng về một số (1: POS, 0: NEU, -1: NEG)\n",
    "- Tìm keyword của phần Description (BERT) (VD: Từ đoạn text \"Harry Potter this year fights Lord Voldemort and his Death Eaters\" -> [\"Harry Potter\", \"Lord Voldemort\", \"Death Eaters\"] -> \"Harry Potter Lord Voldemort Death Eaters\") -> Tính TF-IDF của phần Description giữa review input và toàn bộ review trong database -> Cho ra similarity với Description đầu vào\n",
    "- Tính TF-IDF các mục Authors, Title, Categories -> Cho ra similarity với Authors, Title, Categories đầu vào \n",
    "- Tính kNN (cosine similarity) giữa vector review vừa được thêm vào với tất cả review còn lại rồi trả về top 10 quyển có chỉ số sim cao nhất\n",
    "\n",
    "Cuối cùng là display nó lên cho người dùng xem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Column_1  \\\n",
      "0  fkgJRGzReVkt9YXxKRIhn2PSYa6LAwOPKt2E1PTJyZzrCl...   \n",
      "1  5urEdTyU8NokuawlLucqsWQpmoTCG8BNccgREBkEfbU7LM...   \n",
      "2  mqb2iF81PgShLF6J40VM8ObzdfZjHD2MFOsY7eu4fWWakn...   \n",
      "3  nUHAxFKdKyHLLruu8SYAMCsITNHjCY9zxJnwjOcPOyzLgb...   \n",
      "4  lTa9CVpV3EjwQ7RmIC99aBoBO7sTy1PsThcipEgoFVhFO8...   \n",
      "\n",
      "                                            Column_2  \\\n",
      "0  uE98aER4kUSYlekVZ3RbI9gSWFJyaFRCEGfxLSJsCo3lFT...   \n",
      "1  6bTGZMf1s3jnrvaQ1nhRgGPZs7VTYb1fDIg01OV8OxfT1X...   \n",
      "2  kvIoRgEjrsqEJlvh9Q4z6U4I4qZouOrBc134cEfn7a7zy6...   \n",
      "3  R4hxK4dOHXC9jqkeHvv9fsq3pbVggW45hpICAlXPKC4nsM...   \n",
      "4  OIUqGtMzsqNvEdEcdlArsy8AbmxRPumtqzddOjhXXUYHmT...   \n",
      "\n",
      "                                            Column_3  \\\n",
      "0  sOxyHxVQSLdiIiC4hrDKnynMBTmxP7OX8l0ehFQrgyObbI...   \n",
      "1  D3dl6J3q4iEWqm9GBulXgA8kEtr23RPjQmfUqS6oalsCQS...   \n",
      "2  IvsfYZTxXlOAlNTLKgratcXRUyWDR5B21WlvDtEyX8yV8K...   \n",
      "3  BI2BeVOJLCrZIwBOIlS4NHCy92hK8YDr3MODPatKxTX6Oi...   \n",
      "4  HZsCfmSbaPaptyWCWkGYoyKGnA8pN7cGrlXMN15F83xINd...   \n",
      "\n",
      "                                            Column_4  \\\n",
      "0  fk2zYxzNS49TQdOMAbQln8sXpclsp8KJ0oMxWcKiPXoMir...   \n",
      "1  nwkSQizg4iRDvtXUvLaWJzdHwe0EjL3ODic360TxEmo7S5...   \n",
      "2  wsMm5XE1pPW0djXtEin6sMxXxUog8hBb3N05olSANr8rSj...   \n",
      "3  M8FM4clBnz2AtDQP09mw9IHZ7BrkYyL0TwtBAEsfWOZT3m...   \n",
      "4  rwswAy7ozgCvfNNrpBleEtuIoscU5OkEgfwnem5MzkA5Eo...   \n",
      "\n",
      "                                            Column_5  \\\n",
      "0  ziZfLGrRbJNYmS9jNG01jzvC4bN7lvmL4dER0I59xDd0sF...   \n",
      "1  Add78rvENBbZYXmAmPa82e4PQ2F8re9ycPjRwQGEzPYwhM...   \n",
      "2  TtzAhLw18earckDkZpAFQc6gE8s0qQUoFS0kMlDdvTC82N...   \n",
      "3  KxSrf2178NsPD6JsJSuQ9aBSzbAMmDMUU0X9MnblZ0QivE...   \n",
      "4  JP2kONw7ogMuSVsVAC5HAeT8kWPvnIzpltJLEvaJnAkVFG...   \n",
      "\n",
      "                                            Column_6  \\\n",
      "0  nveu8Iy8iN9OS4DLADnhe5Z3I5BDvIfupdeB5CuzUhTzFl...   \n",
      "1  0l8oZaddRQwUl4HPHUFIZrFOkfHV3wH8W4Zc3m1rmVBFZn...   \n",
      "2  dizLbBpmUyqLemDQ1zMiqmWO7LkvxblNb9bGhODbKxbM5K...   \n",
      "3  USfMA988uGSaRwZXGiIKdsHfPYJ1bt2GF1hMnmZ1oxNHNP...   \n",
      "4  CEHvrg7zpIqymOJCxOOKvW24dihzm4E73dMfASwF6ipR4D...   \n",
      "\n",
      "                                            Column_7  \\\n",
      "0  hbjX295ONF47hDpKx09UXC64Nzg1NlD3Kkr7ulJ5yMh7k2...   \n",
      "1  cnI9ozCCnXM5dRU3Yjc2uW93XgTDJHES6NMkA2fAeHCMuX...   \n",
      "2  ihPz48hPGXtxFstr8k4jWouVSWLqxEVljqtno5PW3GpRFu...   \n",
      "3  ihTVGHt8vJP9ECIPn3FflSd4upU9OKUOjvoCqMTiOvv52J...   \n",
      "4  ccx5aVYFrjJOFbRkjYFUK3yzCzgzAYke9I3djgvVDIICaK...   \n",
      "\n",
      "                                            Column_8  \n",
      "0  ijNSQgfqomcqSAr73idnhsAyPF0EYgpd6YaAJArS6H62Ng...  \n",
      "1  ZwFl41EP5wSHmIpG1QydpbAFIIk2I8hOuGjAAVQ9aY7Hwb...  \n",
      "2  a6wIyxcomp9M7jZcuvFdYh6HcNFkcp6FLf1TKr0NITXfy9...  \n",
      "3  9dVjV4tVpYPnPrl7tRwh3l9soa7jlfGCCdMZHzpIOC9NCW...  \n",
      "4  3mvwaA66rRBJ1AlIgp0qqfwAHSv0JNqoMaiTxDwEvFgBFZ...  \n",
      "0.192 GB\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import string\n",
    "\n",
    "# # Số dòng và số cột\n",
    "# num_rows = 3000000\n",
    "# num_cols = 8\n",
    "# k = 50\n",
    "\n",
    "# # Hàm tạo chuỗi ngẫu nhiên độ dài 100 kí tự\n",
    "# def generate_random_string():\n",
    "#     return ''.join(random.choices(string.ascii_letters + string.digits, k=k))\n",
    "\n",
    "# # Tạo DataFrame với dữ liệu ngẫu nhiên\n",
    "# data = [[generate_random_string() for _ in range(num_cols)] for _ in range(num_rows)]\n",
    "# df = pd.DataFrame(data, columns=[f'Column_{i}' for i in range(1, num_cols + 1)])\n",
    "\n",
    "# # Hiển thị DataFrame\n",
    "# print(df.head(5))\n",
    "\n",
    "# # Kích thước của DataFrame trong byte\n",
    "# size_in_bytes = df.values.nbytes\n",
    "# print(f'{size_in_bytes / 10**9} GB')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
